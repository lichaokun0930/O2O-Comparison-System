"""
æ¨¡ç³ŠåŒ¹é…é‡å¤é—®é¢˜è¯Šæ–­å·¥å…·
è‡ªåŠ¨åˆ†æExcelæŠ¥å‘Šï¼Œè¯†åˆ«é‡å¤åŒ¹é…å’Œå¤šè§„æ ¼å•†å“
"""
import pandas as pd
import re
from collections import Counter
from pathlib import Path
import difflib

def extract_spec_info(product_name):
    """
    ä»å•†å“åç§°ä¸­æå–è§„æ ¼ä¿¡æ¯
    è¿”å›: (åŸºç¡€åç§°, è§„æ ¼åˆ—è¡¨)
    """
    specs = []
    base_name = product_name
    
    # è§„æ ¼æ¨¡å¼ï¼šå®¹é‡ã€é‡é‡ã€æ•°é‡ã€åŒ…è£…
    patterns = [
        r'(\d+\.?\d*)(ml|ML|æ¯«å‡|L|å‡)',           # å®¹é‡
        r'(\d+\.?\d*)(g|G|å…‹|kg|KG|å…¬æ–¤|æ–¤)',      # é‡é‡
        r'(\d+)(ç“¶|ç½|ç›’|è¢‹|åŒ…|ç®±|æ¡¶|æ”¯|æ¡|ç‰‡|å—|åª|ä¸ª|ç²’|æš)', # æ•°é‡+å•ä½
        r'(\d+)x(\d+)(ml|g|ML|G|æ¯«å‡|å…‹)',         # ç»„åˆè£… (å¦‚ 6x500ml)
        r'(å¤§ç“¶|ä¸­ç“¶|å°ç“¶|å¤§åŒ…|ä¸­åŒ…|å°åŒ…|è¿·ä½ è£…|å®¶åº­è£…|åˆ†äº«è£…|ä¾¿æºè£…)', # æè¿°æ€§è§„æ ¼
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, product_name, re.IGNORECASE)
        if matches:
            for match in matches:
                if isinstance(match, tuple):
                    spec = ''.join(match)
                else:
                    spec = match
                specs.append(spec)
                # ä»åŸºç¡€åç§°ä¸­ç§»é™¤è§„æ ¼
                base_name = base_name.replace(spec, '')
    
    # æ¸…ç†åŸºç¡€åç§°
    base_name = re.sub(r'\s+', ' ', base_name).strip()
    base_name = re.sub(r'[ï¼ˆ(].*?[)ï¼‰]', '', base_name)  # ç§»é™¤æ‹¬å·å†…å®¹
    
    return base_name, specs

def calculate_name_similarity(name1, name2):
    """è®¡ç®—ä¸¤ä¸ªå•†å“åçš„æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰"""
    return difflib.SequenceMatcher(None, name1, name2).ratio()

def identify_unique_multi_spec(df, name_col, side_name):
    """
    è¯†åˆ«ç‹¬æœ‰å•†å“ä¸­çš„å¤šè§„æ ¼å•†å“
    
    é€»è¾‘ï¼š
    - æŒ‰å•†å“åç§°åˆ†ç»„ï¼ˆå»é™¤è§„æ ¼æè¿°åï¼‰
    - å¦‚æœåŒä¸€åŸºç¡€åç§°æœ‰å¤šä¸ªä¸åŒè§„æ ¼æˆ–æ¡ç ï¼Œåˆ™ä¸ºå¤šè§„æ ¼
    
    å‚æ•°:
        df: ç‹¬æœ‰å•†å“DataFrame
        name_col: å•†å“åç§°åˆ—å
        side_name: 'æœ¬åº—'æˆ–'ç«å¯¹'ï¼Œç”¨äºè¯†åˆ«è§„æ ¼åˆ—å’Œæ¡ç åˆ—
    
    è¿”å›:
        å¤šè§„æ ¼å•†å“åˆ—è¡¨
    """
    multi_spec_products = []
    
    # è·å–è§„æ ¼åˆ—å’Œæ¡ç åˆ—
    # ç‹¬æœ‰å•†å“Sheetä¸­çš„åˆ—åä¸å¸¦åº—ååç¼€
    spec_cols = [col for col in df.columns if 'è§„æ ¼' in col]
    barcode_cols = [col for col in df.columns if 'æ¡ç ' in col]
    sales_col = 'æœˆå”®' if 'æœˆå”®' in df.columns else None
    
    # æŒ‰å•†å“åç§°åˆ†ç»„ï¼ˆç®€å•åˆ†ç»„ï¼Œå¯ä»¥ä¼˜åŒ–ä¸ºå»é™¤è§„æ ¼åçš„åŸºç¡€åç§°åˆ†ç»„ï¼‰
    for product_name in df[name_col].unique():
        product_rows = df[df[name_col] == product_name]
        
        if len(product_rows) <= 1:
            continue
        
        # æ–¹å¼1ï¼šåŸºäºè§„æ ¼åˆ—
        if spec_cols:
            specs = product_rows[spec_cols[0]].astype(str).str.strip()
            specs = specs[(specs != '') & (specs != 'nan') & (specs.notna())]
            unique_specs = specs.unique()
            
            if len(unique_specs) > 1:
                multi_spec_products.append({
                    'å•†å“åç§°': product_name,
                    'è§„æ ¼æ•°': len(unique_specs),
                    'è§„æ ¼åˆ—è¡¨': ', '.join(unique_specs[:5]),
                    'SKUæ•°': len(product_rows),
                    'æœˆå”®åˆè®¡': product_rows[sales_col].sum() if sales_col else 0,
                    'åˆ¤å®šä¾æ®': f'è§„æ ¼åˆ—æœ‰{len(unique_specs)}ç§ä¸åŒè§„æ ¼'
                })
                continue
        
        # æ–¹å¼2ï¼šåŸºäºæ¡ç åˆ—
        if barcode_cols:
            barcodes = product_rows[barcode_cols[0]].astype(str).str.strip()
            barcodes = barcodes[(barcodes != '') & (barcodes != 'nan') & (barcodes.notna())]
            unique_barcodes = barcodes.unique()
            
            if len(unique_barcodes) > 1:
                multi_spec_products.append({
                    'å•†å“åç§°': product_name,
                    'è§„æ ¼æ•°': len(unique_barcodes),
                    'è§„æ ¼åˆ—è¡¨': f'{len(unique_barcodes)}ä¸ªä¸åŒæ¡ç ',
                    'SKUæ•°': len(product_rows),
                    'æœˆå”®åˆè®¡': product_rows[sales_col].sum() if sales_col else 0,
                    'åˆ¤å®šä¾æ®': f'æ¡ç æœ‰{len(unique_barcodes)}ç§'
                })
    
    return multi_spec_products

def identify_competitor_multi_spec(matched_rows, b_name_col):
    """
    è¯†åˆ«ç«å¯¹çš„å¤šè§„æ ¼å•†å“ï¼ˆåªçœ‹ç«å¯¹ä¾§ï¼‰
    
    æ ¸å¿ƒé€»è¾‘ï¼š
    - å¦‚æœåŒä¸€ä¸ªç«å¯¹å•†å“åï¼ŒåŒ¹é…åˆ°æˆ‘ä»¬å¤šä¸ªä¸åŒçš„å•†å“
    - ä¸”è¿™äº›åŒ¹é…æœ‰ä¸åŒçš„è§„æ ¼æˆ–æ¡ç 
    - è¯´æ˜ç«å¯¹æœ‰å¤šè§„æ ¼ï¼Œè€Œæˆ‘ä»¬å¯èƒ½åªæœ‰å•è§„æ ¼
    
    ç«å¯¹å¤šè§„æ ¼åˆ¤å®šæ¡ä»¶ï¼ˆæ»¡è¶³ä»»æ„ä¸€ç»„ï¼‰ï¼š
    
    ã€æ–¹å¼1ï¼šåŸºäºç«å¯¹è§„æ ¼åˆ—ã€‘
    - åŒä¸€å•†å“åçš„å¤šæ¬¡åŒ¹é…ä¸­ï¼Œç«å¯¹è§„æ ¼åˆ—æœ‰å¤šä¸ªä¸åŒå€¼
    
    ã€æ–¹å¼2ï¼šåŸºäºç«å¯¹æ¡ç ã€‘
    - åŒä¸€å•†å“åçš„å¤šæ¬¡åŒ¹é…ä¸­ï¼Œç«å¯¹æ¡ç æœ‰å¤šä¸ªä¸åŒå€¼
    
    ã€æ–¹å¼3ï¼šåŸºäºç«å¯¹åç§°è§„æ ¼ã€‘
    - ä»ç«å¯¹å•†å“åç§°ä¸­æå–è§„æ ¼ï¼Œæœ‰å¤šä¸ªä¸åŒè§„æ ¼
    
    å‚æ•°ï¼š
        matched_rows: åŒä¸€ç«å¯¹å•†å“åçš„æ‰€æœ‰åŒ¹é…è¡Œ
        b_name_col: ç«å¯¹å•†å“åç§°åˆ—å
    
    è¿”å›ï¼š
        (is_multi_spec, spec_count, spec_list, reason)
    """
    if len(matched_rows) <= 1:
        return False, 1, [], "å•æ¬¡åŒ¹é…"
    
    # è·å–ç«å¯¹è§„æ ¼åˆ—å’Œæ¡ç åˆ—
    spec_b_cols = [col for col in matched_rows.columns if 'è§„æ ¼' in col and b_name_col.split('_')[1] in col]
    barcode_b_cols = [col for col in matched_rows.columns if 'æ¡ç ' in col and b_name_col.split('_')[1] in col]
    
    # === æ–¹å¼1ï¼šåŸºäºç«å¯¹è§„æ ¼åˆ— ===
    if spec_b_cols:
        specs = matched_rows[spec_b_cols[0]].astype(str).str.strip()
        specs = specs[(specs != '') & (specs != 'nan') & (specs.notna())]
        unique_specs = specs.unique()
        
        if len(unique_specs) > 1:
            return True, len(unique_specs), list(unique_specs), f"ç«å¯¹è§„æ ¼åˆ—æœ‰{len(unique_specs)}ç§: {', '.join(unique_specs[:3])}"
    
    # === æ–¹å¼2ï¼šåŸºäºç«å¯¹æ¡ç  ===
    if barcode_b_cols:
        barcodes = matched_rows[barcode_b_cols[0]].astype(str).str.strip()
        barcodes = barcodes[(barcodes != '') & (barcodes != 'nan') & (barcodes.notna())]
        unique_barcodes = barcodes.unique()
        
        if len(unique_barcodes) > 1:
            return True, len(unique_barcodes), list(unique_barcodes), f"ç«å¯¹æ¡ç æœ‰{len(unique_barcodes)}ç§ä¸åŒæ¡ç "
    
    # === æ–¹å¼3ï¼šåŸºäºç«å¯¹åç§°è§„æ ¼è§£æ ===
    b_name = matched_rows[b_name_col].iloc[0]
    _, specs_from_name = extract_spec_info(b_name)
    
    if len(specs_from_name) > 0:
        # å¦‚æœå•†å“åç§°ä¸­åŒ…å«"è§„æ ¼å¯é€‰"ã€"å¤šè§„æ ¼"ç­‰å…³é”®è¯
        if any(keyword in b_name for keyword in ['è§„æ ¼å¯é€‰', 'å¤šè§„æ ¼', 'å°ºç å¯é€‰', 'é¢œè‰²å¯é€‰']):
            return True, 2, specs_from_name, f"ç«å¯¹å•†å“åå«'è§„æ ¼å¯é€‰'ç­‰å…³é”®è¯"
    
    return False, 1, [], "éå¤šè§„æ ¼"

def analyze_match_duplicates(excel_file):
    """
    åˆ†ææ¨¡ç³ŠåŒ¹é…ç»“æœä¸­çš„é‡å¤é—®é¢˜
    
    è¿”å›ï¼šè¯Šæ–­æŠ¥å‘Šå­—å…¸
    """
    print(f"ğŸ“Š æ­£åœ¨åˆ†æ: {excel_file}")
    
    # è¯»å–æ¨¡ç³ŠåŒ¹é…Sheet
    try:
        df = pd.read_excel(excel_file, sheet_name='2-åç§°æ¨¡ç³ŠåŒ¹é…(æ— æ¡ç )')
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–Excel: {e}")
        return None
    
    print(f"âœ… æ¨¡ç³ŠåŒ¹é…æ€»è®°å½•æ•°: {len(df)}")
    
    # æå–ç«å¯¹å•†å“ååˆ—ï¼ˆåŠ¨æ€è¯†åˆ«åˆ—åï¼‰
    b_name_col = None
    a_name_col = None
    name_cols = [col for col in df.columns if 'å•†å“åç§°' in col]
    
    if len(name_cols) >= 2:
        a_name_col = name_cols[0]  # ç¬¬ä¸€ä¸ªå•†å“åç§°åˆ—ä½œä¸ºæœ¬åº—
        b_name_col = name_cols[1]  # ç¬¬äºŒä¸ªå•†å“åç§°åˆ—ä½œä¸ºç«å¯¹
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è¶³å¤Ÿçš„å•†å“åç§°åˆ—ï¼Œå¯ç”¨åˆ—: {df.columns.tolist()}")
        return None
    
    print(f"ğŸ“Œ æœ¬åº—åˆ—: {a_name_col}")
    print(f"ğŸ“Œ ç«å¯¹åˆ—: {b_name_col}")
    
    # === 1. ç«å¯¹ä¾§é‡å¤åˆ†æ ===
    b_duplicates = df[b_name_col].value_counts()
    duplicate_b = b_duplicates[b_duplicates > 1]
    
    print(f"\n{'='*60}")
    print(f"ğŸ“‹ ã€ç«å¯¹ä¾§é‡å¤ç»Ÿè®¡ã€‘")
    print(f"{'='*60}")
    print(f"æ€»åŒ¹é…æ•°: {len(df)}")
    print(f"å”¯ä¸€ç«å¯¹å•†å“æ•°: {df[b_name_col].nunique()}")
    print(f"é‡å¤çš„ç«å¯¹å•†å“æ•°: {len(duplicate_b)}")
    print(f"é‡å¤åŒ¹é…å æ¯”: {len(duplicate_b) * duplicate_b.mean() / len(df) * 100:.1f}%")
    
    # === 2. TOP 10 é‡å¤å•†å“ ===
    print(f"\n{'='*60}")
    print(f"ğŸ”¥ ã€TOP 10 æœ€å¤šé‡å¤çš„ç«å¯¹å•†å“ã€‘")
    print(f"{'='*60}")
    top_duplicates = []
    for b_name, count in duplicate_b.head(10).items():
        matched_a_names = df[df[b_name_col] == b_name][a_name_col].tolist()
        top_duplicates.append({
            'ç«å¯¹å•†å“': b_name,
            'åŒ¹é…æ¬¡æ•°': count,
            'æœ¬åº—å•†å“': matched_a_names
        })
        print(f"\nç«å¯¹: {b_name}")
        print(f"   åŒ¹é…æ¬¡æ•°: {count}")
        print(f"   åŒ¹é…çš„æœ¬åº—å•†å“:")
        for i, a_name in enumerate(matched_a_names, 1):
            print(f"      {i}. {a_name}")
    
    # === 3. å¤šè§„æ ¼ vs çœŸé‡å¤åˆ†ç±» ===
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ ã€å¤šè§„æ ¼å•†å“è¯†åˆ«ã€‘ï¼ˆåŸºäºè§„æ ¼åˆ—+æ¡ç +åç§°ï¼‰")
    print(f"{'='*60}")
    
    # ğŸ” ç»Ÿè®¡ï¼šæ£€æŸ¥æ•°æ®ä¸­è§„æ ¼åˆ—å’Œæ¡ç åˆ—çš„è¦†ç›–ç‡
    spec_cols = [col for col in df.columns if 'è§„æ ¼' in col]
    barcode_cols = [col for col in df.columns if 'æ¡ç ' in col]
    
    if spec_cols:
        spec_coverage_a = df[spec_cols[0]].notna().sum() if len(spec_cols) > 0 else 0
        spec_coverage_b = df[spec_cols[1]].notna().sum() if len(spec_cols) > 1 else 0
        print(f"ğŸ“ è§„æ ¼åˆ—è¦†ç›–: æœ¬åº— {spec_coverage_a}/{len(df)} ({spec_coverage_a/len(df)*100:.1f}%), "
              f"ç«å¯¹ {spec_coverage_b}/{len(df)} ({spec_coverage_b/len(df)*100:.1f}%)")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°è§„æ ¼åˆ—")
    
    if barcode_cols:
        barcode_coverage_a = df[barcode_cols[0]].notna().sum() if len(barcode_cols) > 0 else 0
        barcode_coverage_b = df[barcode_cols[1]].notna().sum() if len(barcode_cols) > 1 else 0
        print(f"ğŸ“Š æ¡ç åˆ—è¦†ç›–: æœ¬åº— {barcode_coverage_a}/{len(df)} ({barcode_coverage_a/len(df)*100:.1f}%), "
              f"ç«å¯¹ {barcode_coverage_b}/{len(df)} ({barcode_coverage_b/len(df)*100:.1f}%)")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°æ¡ç åˆ—")
    
    print()
    
    multi_spec_cases = []
    true_duplicate_cases = []
    
    # ğŸ” ç»Ÿè®¡åˆ¤æ–­è·¯å¾„
    spec_based = 0
    barcode_based = 0
    name_based = 0
    
    for b_name, count in duplicate_b.items():
        if count <= 1:
            continue
            
        matched_rows = df[df[b_name_col] == b_name]
        
        # ğŸ” ä½¿ç”¨æ–°é€»è¾‘ï¼šåªçœ‹ç«å¯¹ä¾§çš„å¤šè§„æ ¼
        is_multi, spec_count, spec_list, reason = identify_competitor_multi_spec(matched_rows, b_name_col)
        
        # ğŸ” ç»Ÿè®¡åˆ¤æ–­è·¯å¾„
        if is_multi:
            if 'è§„æ ¼åˆ—' in reason:
                spec_based += 1
            elif 'æ¡ç ' in reason:
                barcode_based += 1
            else:
                name_based += 1
        
        if is_multi:
            # ç«å¯¹æœ‰å¤šè§„æ ¼ï¼Œè®°å½•ä¸ºå¤šè§„æ ¼æ¡ˆä¾‹
            # è·å–ç«å¯¹çš„è§„æ ¼åˆ—å’Œæ¡ç åˆ—ä¿¡æ¯
            spec_b_cols = [col for col in matched_rows.columns if 'è§„æ ¼' in col and b_name_col.split('_')[1] in col]
            barcode_b_cols = [col for col in matched_rows.columns if 'æ¡ç ' in col and b_name_col.split('_')[1] in col]
            
            # å±•ç¤ºç«å¯¹çš„æ‰€æœ‰è§„æ ¼
            if spec_b_cols:
                competitor_specs = matched_rows[spec_b_cols[0]].dropna().unique()
            else:
                competitor_specs = []
            
            if barcode_b_cols:
                competitor_barcodes = matched_rows[barcode_b_cols[0]].dropna().unique()
            else:
                competitor_barcodes = []
            
            # è·å–æˆ‘ä»¬åŒ¹é…åˆ°çš„å•†å“åˆ—è¡¨
            our_products = matched_rows[a_name_col].tolist()
            
            multi_spec_cases.append({
                'ç«å¯¹å•†å“': b_name,
                'ç«å¯¹è§„æ ¼æ•°': spec_count,
                'ç«å¯¹è§„æ ¼åˆ—è¡¨': ', '.join([str(s) for s in spec_list[:5]]) if spec_list else 'æ— ',
                'æˆ‘ä»¬å•†å“æ•°': len(our_products),
                'æˆ‘ä»¬å•†å“åˆ—è¡¨': '\n'.join([f"{i}. {p}" for i, p in enumerate(our_products[:5], 1)]),
                'åˆ¤å®šä¾æ®': reason
            })
        else:
            # çœŸé‡å¤ï¼šå¤šä¸ªæˆ‘ä»¬çš„å•†å“åŒ¹é…åˆ°åŒä¸€ä¸ªç«å¯¹å•†å“ï¼ˆä¸”ç«å¯¹ä¸æ˜¯å¤šè§„æ ¼ï¼‰
            for idx, row_a in matched_rows.iterrows():
                # æå–åç§°ä¸­çš„è§„æ ¼ä¿¡æ¯ï¼ˆç”¨äºå±•ç¤ºï¼‰
                base_a, specs_a = extract_spec_info(row_a[a_name_col])
                base_b, specs_b = extract_spec_info(b_name)
                
                true_duplicate_cases.append({
                    'æœ¬åº—å•†å“': row_a[a_name_col],
                    'ç«å¯¹å•†å“': b_name,
                    'æœ¬åº—åŸºç¡€å': base_a,
                    'ç«å¯¹åŸºç¡€å': base_b,
                    'åˆ¤å®šä¾æ®': 'éå¤šè§„æ ¼çš„é‡å¤åŒ¹é…'
                })
    
    print(f"âœ… å¤šè§„æ ¼å•†å“å¯¹: {len(multi_spec_cases)}")
    print(f"âŒ çœŸé‡å¤å•†å“å¯¹: {len(true_duplicate_cases)}")
    if len(multi_spec_cases) + len(true_duplicate_cases) > 0:
        print(f"ğŸ“Š å¤šè§„æ ¼å æ¯”: {len(multi_spec_cases) / (len(multi_spec_cases) + len(true_duplicate_cases)) * 100:.1f}%")
    
    # ğŸ” æ˜¾ç¤ºåˆ¤æ–­è·¯å¾„ç»Ÿè®¡
    if multi_spec_cases:
        print(f"\nğŸ“‹ å¤šè§„æ ¼åˆ¤å®šè·¯å¾„ç»Ÿè®¡:")
        print(f"   - åŸºäºè§„æ ¼åˆ—: {spec_based} å¯¹")
        print(f"   - åŸºäºæ¡ç : {barcode_based} å¯¹")
        print(f"   - åŸºäºåç§°è§£æ: {name_based} å¯¹")
    
    # å±•ç¤ºå¤šè§„æ ¼è¯†åˆ«è¯¦æƒ…
    if multi_spec_cases:
        print(f"\nğŸ” ã€ç«å¯¹å¤šè§„æ ¼å•†å“ç¤ºä¾‹ã€‘ï¼ˆå‰5ä¸ªï¼‰")
        for i, case in enumerate(multi_spec_cases[:5], 1):
            print(f"\n  {i}. ç«å¯¹: {case['ç«å¯¹å•†å“'][:80]}")
            print(f"     âš ï¸  ç«å¯¹æœ‰ {case['ç«å¯¹è§„æ ¼æ•°']} ç§è§„æ ¼: {case['ç«å¯¹è§„æ ¼åˆ—è¡¨']}")
            print(f"     ğŸ“Š æˆ‘ä»¬åªæœ‰ {case['æˆ‘ä»¬å•†å“æ•°']} ä¸ªå•†å“åŒ¹é…")
            print(f"     âœ… {case['åˆ¤å®šä¾æ®']}")
            print(f"     æˆ‘ä»¬çš„å•†å“:")
            print(f"     {case['æˆ‘ä»¬å•†å“åˆ—è¡¨']}")
    
    # === 4. ç‹¬æœ‰å•†å“çš„å¤šè§„æ ¼åˆ†æ ===
    print(f"\n{'='*60}")
    print(f"ğŸ”¬ ã€ç‹¬æœ‰å•†å“å¤šè§„æ ¼åˆ†æã€‘")
    print(f"{'='*60}")
    
    # å°è¯•è¯»å–ç‹¬æœ‰å•†å“Sheet
    competitor_unique_multi = []
    our_unique_multi = []
    
    try:
        # è¯»å–æ‰€æœ‰Sheetåç§°
        xl = pd.ExcelFile(excel_file)
        sheet_names = xl.sheet_names
        
        # åŠ¨æ€è¯†åˆ«ç‹¬æœ‰å•†å“Sheetï¼ˆæ ¼å¼ï¼šåº—å-ç‹¬æœ‰å•†å“(å…¨éƒ¨)ï¼‰
        competitor_sheet = None
        our_sheet = None
        
        for sheet in sheet_names:
            if 'ç‹¬æœ‰å•†å“(å…¨éƒ¨)' in sheet:
                # æ ¹æ®åˆ—ååˆ¤æ–­æ˜¯ç«å¯¹è¿˜æ˜¯æœ¬åº—
                # ç«å¯¹SheetåŒ…å«b_name_colï¼Œæœ¬åº—SheetåŒ…å«a_name_col
                if b_name_col.split('_')[1] in sheet:
                    competitor_sheet = sheet
                elif a_name_col.split('_')[1] in sheet:
                    our_sheet = sheet
        
        # è¯»å–ç«å¯¹ç‹¬æœ‰å•†å“
        if competitor_sheet:
            df_competitor_unique = pd.read_excel(excel_file, sheet_name=competitor_sheet)
            print(f"ğŸ“Š ç«å¯¹ç‹¬æœ‰å•†å“æ€»æ•°: {len(df_competitor_unique)} (Sheet: {competitor_sheet})")
            
            # ç‹¬æœ‰å•†å“Sheetä½¿ç”¨ç®€å•çš„"å•†å“åç§°"åˆ—ï¼ˆä¸å¸¦åº—ååç¼€ï¼‰
            name_col = 'å•†å“åç§°'
            if name_col not in df_competitor_unique.columns:
                print(f"âš ï¸  åˆ—åé”™è¯¯: ç«å¯¹ç‹¬æœ‰å•†å“Sheetä¸­æ‰¾ä¸åˆ°'å•†å“åç§°'åˆ—")
                print(f"   å®é™…åˆ—å: {list(df_competitor_unique.columns)[:10]}")
            else:
                # è¯†åˆ«ç«å¯¹ç‹¬æœ‰å•†å“ä¸­çš„å¤šè§„æ ¼
                competitor_unique_multi = identify_unique_multi_spec(df_competitor_unique, name_col, 'ç«å¯¹')
                print(f"âœ… ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“: {len(competitor_unique_multi)} ä¸ª")
                
                if competitor_unique_multi:
                    # æŒ‰æœˆå”®æ’åº
                    competitor_unique_multi_df = pd.DataFrame(competitor_unique_multi)
                    competitor_unique_multi_df = competitor_unique_multi_df.sort_values('æœˆå”®åˆè®¡', ascending=False)
                    competitor_unique_multi = competitor_unique_multi_df.to_dict('records')
                    
                    print(f"\nğŸ”¥ TOP 5 é«˜é”€é‡ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“:")
                    for i, item in enumerate(competitor_unique_multi[:5], 1):
                        print(f"  {i}. {item['å•†å“åç§°'][:60]}")
                        print(f"     è§„æ ¼æ•°: {item['è§„æ ¼æ•°']}, SKUæ•°: {item['SKUæ•°']}, æœˆå”®: {item['æœˆå”®åˆè®¡']}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°ç«å¯¹ç‹¬æœ‰å•†å“Sheet")
    except Exception as e:
        print(f"âš ï¸  è¯»å–ç«å¯¹ç‹¬æœ‰å•†å“é”™è¯¯: {e}")
    
    try:
        # è¯»å–æˆ‘ä»¬ç‹¬æœ‰å•†å“
        if our_sheet:
            df_our_unique = pd.read_excel(excel_file, sheet_name=our_sheet)
            print(f"\nğŸ“Š æœ¬åº—ç‹¬æœ‰å•†å“æ€»æ•°: {len(df_our_unique)} (Sheet: {our_sheet})")
            
            # ç‹¬æœ‰å•†å“Sheetä½¿ç”¨ç®€å•çš„"å•†å“åç§°"åˆ—ï¼ˆä¸å¸¦åº—ååç¼€ï¼‰
            name_col = 'å•†å“åç§°'
            if name_col not in df_our_unique.columns:
                print(f"âš ï¸  åˆ—åé”™è¯¯: æœ¬åº—ç‹¬æœ‰å•†å“Sheetä¸­æ‰¾ä¸åˆ°'å•†å“åç§°'åˆ—")
                print(f"   å®é™…åˆ—å: {list(df_our_unique.columns)[:10]}")
            else:
                # è¯†åˆ«æˆ‘ä»¬ç‹¬æœ‰å•†å“ä¸­çš„å¤šè§„æ ¼
                our_unique_multi = identify_unique_multi_spec(df_our_unique, name_col, 'æœ¬åº—')
                print(f"âœ… æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“: {len(our_unique_multi)} ä¸ª")
                
                if our_unique_multi:
                    # æŒ‰æœˆå”®æ’åº
                    our_unique_multi_df = pd.DataFrame(our_unique_multi)
                    our_unique_multi_df = our_unique_multi_df.sort_values('æœˆå”®åˆè®¡', ascending=False)
                    our_unique_multi = our_unique_multi_df.to_dict('records')
                    
                    print(f"\nâœ¨ TOP 5 é«˜é”€é‡æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“:")
                    for i, item in enumerate(our_unique_multi[:5], 1):
                        print(f"  {i}. {item['å•†å“åç§°'][:60]}")
                        print(f"     è§„æ ¼æ•°: {item['è§„æ ¼æ•°']}, SKUæ•°: {item['SKUæ•°']}, æœˆå”®: {item['æœˆå”®åˆè®¡']}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°æœ¬åº—ç‹¬æœ‰å•†å“Sheet")
    except Exception as e:
        print(f"âš ï¸  è¯»å–æœ¬åº—ç‹¬æœ‰å•†å“é”™è¯¯: {e}")
    
    # === 5. å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š ===
    output_file = excel_file.replace('.xlsx', '_é‡å¤è¯Šæ–­æŠ¥å‘Š.xlsx')
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # Sheet 1: æ¦‚è§ˆ
        summary_data = {
            'æŒ‡æ ‡': [
                'æ€»åŒ¹é…æ•°',
                'å”¯ä¸€ç«å¯¹å•†å“æ•°',
                'é‡å¤çš„ç«å¯¹å•†å“æ•°',
                'é‡å¤åŒ¹é…æ€»æ•°',
                'å¤šè§„æ ¼å•†å“å¯¹',
                'çœŸé‡å¤å•†å“å¯¹',
                'å¤šè§„æ ¼å æ¯”(%)'
            ],
            'æ•°å€¼': [
                len(df),
                df[b_name_col].nunique(),
                len(duplicate_b),
                duplicate_b.sum() - len(duplicate_b),
                len(multi_spec_cases),
                len(true_duplicate_cases),
                f"{len(multi_spec_cases) / max(len(multi_spec_cases) + len(true_duplicate_cases), 1) * 100:.1f}"
            ]
        }
        pd.DataFrame(summary_data).to_excel(writer, sheet_name='è¯Šæ–­æ¦‚è§ˆ', index=False)
        
        # Sheet 2: TOPé‡å¤å•†å“
        top_df_data = []
        for item in top_duplicates:
            for i, a_name in enumerate(item['æœ¬åº—å•†å“']):
                top_df_data.append({
                    'ç«å¯¹å•†å“': item['ç«å¯¹å•†å“'],
                    'åŒ¹é…æ¬¡æ•°': item['åŒ¹é…æ¬¡æ•°'] if i == 0 else '',
                    'æœ¬åº—å•†å“': a_name
                })
        pd.DataFrame(top_df_data).to_excel(writer, sheet_name='TOP10é‡å¤å•†å“', index=False)
        
        # Sheet 3: å¤šè§„æ ¼å•†å“
        if multi_spec_cases:
            pd.DataFrame(multi_spec_cases).to_excel(writer, sheet_name='å¤šè§„æ ¼å•†å“', index=False)
        
        # Sheet 4: çœŸé‡å¤å•†å“
        if true_duplicate_cases:
            pd.DataFrame(true_duplicate_cases).to_excel(writer, sheet_name='çœŸé‡å¤å•†å“', index=False)
        
        # Sheet 5: å®Œæ•´é‡å¤åˆ—è¡¨
        duplicate_df = df[df[b_name_col].isin(duplicate_b.index)].copy()
        duplicate_df = duplicate_df.sort_values(b_name_col)
        duplicate_df.to_excel(writer, sheet_name='å®Œæ•´é‡å¤åˆ—è¡¨', index=False)
        
        # Sheet 6: ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼åˆ†æ
        if competitor_unique_multi:
            competitor_unique_df = pd.DataFrame(competitor_unique_multi)
            # æŒ‰æœˆå”®é™åºæ’åˆ—
            competitor_unique_df = competitor_unique_df.sort_values('æœˆå”®åˆè®¡', ascending=False)
            competitor_unique_df.to_excel(writer, sheet_name='ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“', index=False)
            print(f"âœ… Sheet 6: ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“ ({len(competitor_unique_multi)}ä¸ª)")
        else:
            # åˆ›å»ºç©ºSheet
            pd.DataFrame({'è¯´æ˜': ['æ— ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“æˆ–æœªæ‰¾åˆ°ç‹¬æœ‰å•†å“æ•°æ®']}).to_excel(
                writer, sheet_name='ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“', index=False)
            print(f"âš ï¸  Sheet 6: ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼å•†å“ (æœªæ‰¾åˆ°æ•°æ®)")
        
        # Sheet 7: æˆ‘ä»¬ç‹¬æœ‰å¤šè§„æ ¼åˆ†æ
        if our_unique_multi:
            our_unique_df = pd.DataFrame(our_unique_multi)
            # æŒ‰æœˆå”®é™åºæ’åˆ—
            our_unique_df = our_unique_df.sort_values('æœˆå”®åˆè®¡', ascending=False)
            our_unique_df.to_excel(writer, sheet_name='æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“', index=False)
            print(f"âœ… Sheet 7: æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“ ({len(our_unique_multi)}ä¸ª)")
        else:
            # åˆ›å»ºç©ºSheet
            pd.DataFrame({'è¯´æ˜': ['æ— æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“æˆ–æœªæ‰¾åˆ°ç‹¬æœ‰å•†å“æ•°æ®']}).to_excel(
                writer, sheet_name='æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“', index=False)
            print(f"âš ï¸  Sheet 7: æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼å•†å“ (æœªæ‰¾åˆ°æ•°æ®)")
        
        # Sheet 8: å¤šè§„æ ¼æˆ˜ç•¥æ€»è§ˆ
        strategy_data = {
            'ç»´åº¦': [
                'ã€å·²åŒ¹é…ã€‘ç«å¯¹å¤šè§„æ ¼å•†å“',
                'ã€å·²åŒ¹é…ã€‘çœŸé‡å¤å•†å“',
                'ã€ç«å¯¹ç‹¬æœ‰ã€‘å¤šè§„æ ¼å•†å“',
                'ã€æœ¬åº—ç‹¬æœ‰ã€‘å¤šè§„æ ¼å•†å“',
                '',
                'ä¼˜å…ˆçº§P0',
                'ä¼˜å…ˆçº§P1',
                'ä¼˜å…ˆçº§P2'
            ],
            'æ•°é‡': [
                len(multi_spec_cases),
                len(true_duplicate_cases),
                len(competitor_unique_multi),
                len(our_unique_multi),
                '',
                f"{len(multi_spec_cases)} å¯¹",
                f"{len(competitor_unique_multi)} ä¸ª",
                f"{len(our_unique_multi)} ä¸ª"
            ],
            'ä¸šåŠ¡å«ä¹‰': [
                'ç«å¯¹è§„æ ¼æ›´å…¨ï¼Œæˆ‘ä»¬éœ€è¡¥é½',
                'éå¤šè§„æ ¼çš„é‡å¤åŒ¹é…',
                'æˆ‘ä»¬æ²¡æœ‰çš„å“ç±»',
                'æˆ‘ä»¬çš„å·®å¼‚åŒ–å•†å“',
                '',
                'è¡¥é½å·²åŒ¹é…çš„å¤šè§„æ ¼',
                'å¼•è¿›é«˜é”€é‡ç«å¯¹ç‹¬æœ‰å¤šè§„æ ¼',
                'å¼ºåŒ–æ¨å¹¿æœ¬åº—ç‹¬æœ‰å¤šè§„æ ¼'
            ],
            'æ“ä½œå»ºè®®': [
                'è§Sheet 3ï¼Œé€ä¸€è¡¥é½è§„æ ¼',
                'å¯ç”¨ç«å¯¹ä¾§å»é‡ï¼ˆå·²ä¿®å¤ä¸»ç¨‹åºï¼‰',
                'è§Sheet 6ï¼ŒæŒ‰æœˆå”®è¯„ä¼°å¼•è¿›ä»·å€¼',
                'è§Sheet 7ï¼ŒåŠ å¼ºè¥é”€çªå‡ºä¼˜åŠ¿',
                '',
                'å¿«é€Ÿæå‡ç«äº‰åŠ›ï¼Œç«‹å³æ‰§è¡Œ',
                'æˆ˜ç•¥å“ç±»æ‰©å¼ ï¼ŒæŒ‰é”€é‡ä¼˜å…ˆ',
                'å·©å›ºå·®å¼‚åŒ–ä¼˜åŠ¿ï¼ŒæŒç»­æ¨å¹¿'
            ]
        }
        strategy_df = pd.DataFrame(strategy_data)
        strategy_df.to_excel(writer, sheet_name='å¤šè§„æ ¼æˆ˜ç•¥æ€»è§ˆ', index=False)
        print(f"âœ… Sheet 8: å¤šè§„æ ¼æˆ˜ç•¥æ€»è§ˆ")
    
    print(f"\n{'='*60}")
    print(f"âœ… è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
    print(f"{'='*60}")
    
    return {
        'total_matches': len(df),
        'unique_b': df[b_name_col].nunique(),
        'duplicate_b_count': len(duplicate_b),
        'multi_spec_count': len(multi_spec_cases),
        'true_duplicate_count': len(true_duplicate_cases),
        'competitor_unique_multi_count': len(competitor_unique_multi),
        'our_unique_multi_count': len(our_unique_multi),
        'output_file': output_file
    }

def main():
    """ä¸»å‡½æ•°ï¼šæŸ¥æ‰¾æœ€æ–°çš„æ¯”ä»·æŠ¥å‘Šå¹¶åˆ†æ"""
    # æŸ¥æ‰¾reportsç›®å½•ä¸‹æœ€æ–°çš„æ¯”ä»·æŠ¥å‘Š
    reports_dir = Path('reports')
    
    if not reports_dir.exists():
        print("âŒ æ‰¾ä¸åˆ° reports ç›®å½•")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰æ¯”ä»·æŠ¥å‘Šï¼ˆæ’é™¤è¯Šæ–­æŠ¥å‘Šï¼‰
    excel_files = [f for f in reports_dir.glob('matched_products_comparison_final_*.xlsx') 
                   if 'è¯Šæ–­' not in f.name]
    
    if not excel_files:
        print("âŒ æ‰¾ä¸åˆ°æ¯”ä»·æŠ¥å‘Šæ–‡ä»¶")
        return
    
    # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(excel_files, key=lambda x: x.stat().st_mtime)
    
    print(f"ğŸ¯ æ‰¾åˆ°æœ€æ–°æŠ¥å‘Š: {latest_file.name}")
    print(f"ğŸ“… ä¿®æ”¹æ—¶é—´: {pd.Timestamp.fromtimestamp(latest_file.stat().st_mtime)}")
    print()
    
    # æ‰§è¡Œåˆ†æ
    result = analyze_match_duplicates(str(latest_file))
    
    if result:
        print(f"\n{'='*60}")
        print(f"ğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"{'='*60}")
        print(f"å»ºè®®ï¼š")
        
        duplicate_ratio = result['duplicate_b_count'] / result['unique_b'] * 100
        multi_spec_ratio = result['multi_spec_count'] / max(result['multi_spec_count'] + result['true_duplicate_count'], 1) * 100
        
        if duplicate_ratio > 30:
            print(f"âš ï¸  é‡å¤å•†å“å æ¯” {duplicate_ratio:.1f}% è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–åŒ¹é…é€»è¾‘")
        
        if multi_spec_ratio > 70:
            print(f"âœ… å¤šè§„æ ¼å•†å“å æ¯” {multi_spec_ratio:.1f}%ï¼Œå¯å•ç‹¬Sheetå±•ç¤º")
        elif multi_spec_ratio < 30:
            print(f"âš ï¸  çœŸé‡å¤å•†å“å æ¯” {100-multi_spec_ratio:.1f}%ï¼Œå»ºè®®å¯ç”¨ç«å¯¹ä¾§å»é‡")
        else:
            print(f"ğŸ“Š å¤šè§„æ ¼({multi_spec_ratio:.1f}%) å’ŒçœŸé‡å¤ æ··åˆï¼Œå»ºè®®åˆ†åˆ«å¤„ç†")

if __name__ == '__main__':
    main()
