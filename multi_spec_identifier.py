"""
å®Œæ•´ç‰ˆå¤šè§„æ ¼å•†å“è¯†åˆ«å·¥å…·
åŸºäºä¸‰ä¿¡å·æ£€æµ‹æœºåˆ¶ï¼ˆè§„æ ¼åˆ— + åç§°è§£æ + æ¡ç å¤šå€¼ï¼‰

å‚è€ƒæ–‡æ¡£: å¤šè§„æ ¼å•†å“è¯†åˆ«é€»è¾‘è¯´æ˜.md
å®ç°: identify_multi_spec_products() å®Œæ•´ç‰ˆ
"""
import pandas as pd
import numpy as np
import re
from typing import Tuple, List, Set


def _extract_inferred_spec(name: str) -> str:
    """
    ä»å•†å“åç§°ä¸­æå–è§„æ ¼ä¿¡æ¯
    
    å‚æ•°:
        name: å•†å“åç§°
    
    è¿”å›:
        ç©ºæ ¼åˆ†éš”çš„è§„æ ¼æ ‡è®°å­—ç¬¦ä¸² (å¦‚ "500ml æ— ç³–")
    """
    if not isinstance(name, str) or not name.strip():
        return ''
    
    specs = []
    
    # === è§„æ ¼æ¨¡å¼ï¼šæ•°é‡Ã—è§„æ ¼ ===
    # ç¤ºä¾‹: 12*50g, 6Ã—500ml, 3x1.5L
    pattern_qty_spec = r'(\d+\s*[xÃ—*]\s*\d+(?:\.\d+)?\s*(?:g|kg|ml|l|ç‰‡|åŒ…|è¢‹|æ”¯|æš|ç“¶|å¬|å·)?)'
    matches = re.findall(pattern_qty_spec, name, re.IGNORECASE)
    for match in matches:
        specs.append(match.replace(' ', '').lower())
    
    # === è§„æ ¼æ¨¡å¼ï¼šå®¹é‡/é‡é‡ ===
    # ç¤ºä¾‹: 500ml, 1.5l, 300g, 2kg
    pattern_volume_weight = r'(\d+(?:\.\d+)?\s*(?:ml|l|g|kg))'
    matches = re.findall(pattern_volume_weight, name, re.IGNORECASE)
    for match in matches:
        specs.append(match.replace(' ', '').lower())
    
    # === è§„æ ¼æ¨¡å¼ï¼šæ•°é‡å•ä½ ===
    # ç¤ºä¾‹: 12ç‰‡, 6åŒ…, 24æ”¯
    pattern_count = r'(\d+\s*(?:ç‰‡|åŒ…|è¢‹|æ”¯|æš|ç“¶|å¬|ç›’|å·|å—|ç‰‡è£…|è¢‹è£…|æ”¯è£…))'
    matches = re.findall(pattern_count, name, re.IGNORECASE)
    for match in matches:
        specs.append(match.replace(' ', ''))
    
    # === å£å‘³/å˜ä½“å…³é”®è¯ ===
    flavor_keywords = [
        'åŸå‘³', 'è‰è“', 'é¦™è‰', 'å·§å…‹åŠ›', 'æŸ æª¬', 'èŠ’æœ', 'è“è“', 'è‘¡è„',
        'å¾®è¾£', 'ä¸­è¾£', 'ç‰¹è¾£', 'éº»è¾£', 'é¦™è¾£',
        'æ— ç³–', 'ä½ç³–', '0ç³–', 'é›¶ç³–', 'å‡ç³–',
        'å®¶åº­è£…', 'åˆ†äº«è£…', 'é‡è´©', 'è¿·ä½ ', 'mini', 'MINI',
        'å¤§ç“¶', 'ä¸­ç“¶', 'å°ç“¶', 'å¤§åŒ…', 'ä¸­åŒ…', 'å°åŒ…',
        'å¤§', 'ä¸­', 'å°', 'ç‰¹å¤§', 'åŠ å¤§',
        'åŸå‘³å‹', 'æ¸…çˆ½å‹', 'æµ“éƒå‹',
    ]
    
    for keyword in flavor_keywords:
        if keyword in name:
            specs.append(keyword)
    
    # å»é‡å¹¶ä¿æŒé¡ºåº
    unique_specs = []
    seen = set()
    for spec in specs:
        if spec not in seen:
            unique_specs.append(spec)
            seen.add(spec)
    
    return ' '.join(unique_specs)


def _normalize_base_name(name: str) -> str:
    """
    æ ‡å‡†åŒ–å•†å“åç§°ï¼Œç§»é™¤è§„æ ¼ä¿¡æ¯ç”ŸæˆåŸºç¡€åç§°
    
    å‚æ•°:
        name: å•†å“åç§°
    
    è¿”å›:
        æ ‡å‡†åŒ–åçš„åŸºç¡€åç§° (å¦‚ "å¯å£å¯ä¹")
    """
    if not isinstance(name, str) or not name.strip():
        return ''
    
    s = name.lower()
    
    # 1. ç§»é™¤æ‹¬å·å†…å®¹
    s = re.sub(r'[\(ï¼ˆ\[][^\)ï¼‰\]]*[\)ï¼‰\]]', '', s)
    
    # 2. ç§»é™¤æ•°é‡Ã—è§„æ ¼æ¨¡å¼
    s = re.sub(r'\d+\s*[xÃ—*]\s*\d+(?:\.\d+)?\s*(?:g|kg|ml|l|ç‰‡|åŒ…|è¢‹|æ”¯|æš|ç“¶|å¬|å·)?', '', s, flags=re.IGNORECASE)
    
    # 3. ç§»é™¤å®¹é‡/é‡é‡æ¨¡å¼
    s = re.sub(r'\d+(?:\.\d+)?\s*(?:ml|l|g|kg)', '', s, flags=re.IGNORECASE)
    
    # 4. ç§»é™¤æ•°é‡å•ä½æ¨¡å¼
    s = re.sub(r'\d+\s*(?:ç‰‡|åŒ…|è¢‹|æ”¯|æš|ç“¶|å¬|ç›’|å·|å—|ç‰‡è£…|è¢‹è£…|æ”¯è£…)', '', s)
    
    # 5. ç§»é™¤å£å‘³/å˜ä½“å…³é”®è¯
    variant_keywords = [
        'åŸå‘³', 'è‰è“', 'é¦™è‰', 'å·§å…‹åŠ›', 'æŸ æª¬', 'èŠ’æœ', 'è“è“', 'è‘¡è„',
        'å¾®è¾£', 'ä¸­è¾£', 'ç‰¹è¾£', 'éº»è¾£', 'é¦™è¾£',
        'æ— ç³–', 'ä½ç³–', '0ç³–', 'é›¶ç³–', 'å‡ç³–',
        'å®¶åº­è£…', 'åˆ†äº«è£…', 'é‡è´©', 'è¿·ä½ ', 'mini', 'MINI',
        'å¤§ç“¶', 'ä¸­ç“¶', 'å°ç“¶', 'å¤§åŒ…', 'ä¸­åŒ…', 'å°åŒ…',
        'å¤§', 'ä¸­', 'å°', 'ç‰¹å¤§', 'åŠ å¤§',
        'åŸå‘³å‹', 'æ¸…çˆ½å‹', 'æµ“éƒå‹',
    ]
    
    for keyword in variant_keywords:
        s = s.replace(keyword.lower(), '')
    
    # 6. æ¸…ç†æ ‡ç‚¹ç¬¦å·å’Œå¤šä½™ç©ºæ ¼
    s = re.sub(r'[^\u4e00-\u9fff0-9a-zA-Z]+', ' ', s)
    s = re.sub(r'\s+', ' ', s).strip()
    
    return s


def identify_multi_spec_products(df: pd.DataFrame, 
                                  product_name_col: str = 'product_name',
                                  spec_col: str = 'è§„æ ¼åç§°',
                                  barcode_col: str = 'barcode',
                                  store_col: str = None) -> pd.DataFrame:
    """
    è¯†åˆ«å¤šè§„æ ¼å•†å“ï¼ˆä¸‰ä¿¡å·æ£€æµ‹æœºåˆ¶ï¼‰
    
    æ£€æµ‹é€»è¾‘ï¼š
    - Signal 1: è§„æ ¼åˆ—å¤šå€¼ï¼ˆæœ€å¯é ï¼‰- åŒä¸€å•†å“åä¸‹æœ‰å¤šä¸ªä¸åŒè§„æ ¼å€¼
    - Signal 2: åç§°è§£æå¤šå€¼ï¼ˆæ™ºèƒ½æ¨æ–­ï¼‰- åŒä¸€åŸºç¡€åç§°ä¸‹æœ‰å¤šä¸ªä¸åŒè§„æ ¼
    - Signal 3: æ¡ç å¤šå€¼ï¼ˆå…œåº•æœºåˆ¶ï¼‰- åŒä¸€åŸºç¡€åç§°ä¸‹æœ‰å¤šä¸ªä¸åŒæ¡ç 
    
    å‚æ•°:
        df: åŸå§‹å•†å“DataFrame
        product_name_col: å•†å“åç§°åˆ—å
        spec_col: è§„æ ¼åˆ—åï¼ˆå¯é€‰ï¼Œå¦‚ä¸å­˜åœ¨åˆ™è·³è¿‡Signal 1ï¼‰
        barcode_col: æ¡ç åˆ—åï¼ˆå¯é€‰ï¼Œå¦‚ä¸å­˜åœ¨åˆ™è·³è¿‡Signal 3ï¼‰
        store_col: é—¨åº—åˆ—åï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šé—¨åº—æ•°æ®ï¼‰
    
    è¿”å›:
        å¤šè§„æ ¼å•†å“DataFrameï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š
        - product_name: åŸå§‹å•†å“åç§°
        - base_name: æ ‡å‡†åŒ–åŸºç¡€åç§°
        - è§„æ ¼åç§°: åŸå§‹è§„æ ¼åˆ—ï¼ˆå¦‚å­˜åœ¨ï¼‰
        - inferred_spec: ä»åç§°è§£æçš„è§„æ ¼
        - variant_key: å”¯ä¸€è§„æ ¼æ ‡è¯†ï¼ˆä¼˜å…ˆçº§ï¼šè§„æ ¼åˆ— > inferred_spec > barcodeï¼‰
        - è§„æ ¼ç§ç±»æ•°: è¯¥å•†å“çš„è§„æ ¼å˜ä½“æ•°é‡
        - å¤šè§„æ ¼ä¾æ®: è§¦å‘çš„ä¿¡å·æºï¼ˆè§„æ ¼åˆ—/åç§°è§£æ/æ¡ç å¤šå€¼ï¼‰
    """
    print("ğŸ” å¼€å§‹è¯†åˆ«å¤šè§„æ ¼å•†å“...")
    
    # === Step 1: æ•°æ®é¢„å¤„ç† ===
    work = df.copy()
    
    # ç¡®ä¿å•†å“åç§°åˆ—å­˜åœ¨
    if product_name_col not in work.columns:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å•†å“åç§°åˆ— '{product_name_col}'")
        return pd.DataFrame()
    
    # æ ‡å‡†åŒ–è§„æ ¼åˆ—ï¼ˆå¤„ç†Noneã€ç©ºå­—ç¬¦ä¸²ï¼‰
    if spec_col in work.columns:
        work[spec_col] = work[spec_col].where(~work[spec_col].isna(), None)
        work[spec_col] = work[spec_col].apply(lambda x: x.strip() if isinstance(x, str) else x)
        work.loc[work[spec_col] == '', spec_col] = None
    else:
        work[spec_col] = None
        print(f"  âš ï¸ æœªæ‰¾åˆ°è§„æ ¼åˆ— '{spec_col}'ï¼Œè·³è¿‡Signal 1")
    
    # === Step 2: ç”Ÿæˆè¾…åŠ©åˆ— ===
    print("  ğŸ“ ç”Ÿæˆè¾…åŠ©åˆ—...")
    work['inferred_spec'] = work[product_name_col].apply(_extract_inferred_spec)
    work['base_name'] = work[product_name_col].apply(_normalize_base_name)
    
    # === Step 3: å®šä¹‰åˆ†ç»„é”®ï¼ˆæ”¯æŒå¤šé—¨åº—ï¼‰===
    has_store = store_col is not None and store_col in work.columns
    key_pn = [store_col, product_name_col] if has_store else [product_name_col]
    key_base = [store_col, 'base_name'] if has_store else ['base_name']
    
    if has_store:
        print(f"  ğŸª æ£€æµ‹åˆ°å¤šé—¨åº—æ•°æ®ï¼ŒæŒ‰ '{store_col}' åˆ†ç»„")
    
    # === Step 4: ä¸‰ä¿¡å·æ£€æµ‹ ===
    print("  ğŸ¯ æ‰§è¡Œä¸‰ä¿¡å·æ£€æµ‹...")
    
    # Signal 1: è§„æ ¼åˆ—å¤šå€¼
    if spec_col in work.columns and work[spec_col].notna().any():
        sig1 = work.dropna(subset=[spec_col]).groupby(key_pn)[spec_col].nunique(dropna=True)
        sig1_keys = sig1[sig1 > 1].index
        print(f"     âœ… Signal 1 (è§„æ ¼åˆ—): {len(sig1_keys)} ä¸ªå•†å“")
    else:
        sig1_keys = pd.Index([]) if not has_store else pd.MultiIndex.from_tuples([])
        print(f"     âš ï¸ Signal 1 (è§„æ ¼åˆ—): è·³è¿‡")
    
    # Signal 2: åç§°è§£æå¤šå€¼
    sig2 = work[work['inferred_spec'] != ''].groupby(key_base)['inferred_spec'].nunique()
    sig2_keys = sig2[sig2 > 1].index
    print(f"     âœ… Signal 2 (åç§°è§£æ): {len(sig2_keys)} ä¸ªåŸºç¡€åç§°")
    
    # Signal 3: æ¡ç å¤šå€¼
    if barcode_col in work.columns:
        tmp = work.copy()
        tmp[barcode_col] = tmp[barcode_col].astype(str)
        # è¿‡æ»¤æ‰ç©ºå€¼å’Œnan
        tmp = tmp[tmp[barcode_col].notna() & (tmp[barcode_col] != '') & (tmp[barcode_col] != 'nan')]
        if len(tmp) > 0:
            sig3 = tmp.groupby(key_base)[barcode_col].nunique()
            sig3_keys = sig3[sig3 > 1].index
            print(f"     âœ… Signal 3 (æ¡ç å¤šå€¼): {len(sig3_keys)} ä¸ªåŸºç¡€åç§°")
        else:
            sig3_keys = pd.Index([]) if not has_store else pd.MultiIndex.from_tuples([])
            print(f"     âš ï¸ Signal 3 (æ¡ç å¤šå€¼): æ— æœ‰æ•ˆæ¡ç æ•°æ®")
    else:
        sig3_keys = pd.Index([]) if not has_store else pd.MultiIndex.from_tuples([])
        print(f"     âš ï¸ Signal 3 (æ¡ç å¤šå€¼): è·³è¿‡")
    
    # === Step 5: åˆå¹¶ä¿¡å·æºï¼Œæ”¶é›†æ‰€æœ‰å¤šè§„æ ¼base_names ===
    print("  ğŸ”— åˆå¹¶ä¿¡å·æº...")
    
    def idx_to_df(keys, cols):
        """å°†Index/MultiIndexè½¬æ¢ä¸ºDataFrame"""
        if len(keys) == 0:
            return pd.DataFrame(columns=cols)
        
        if isinstance(keys, pd.MultiIndex):
            df = keys.to_frame(index=False)
            df.columns = cols
            return df
        else:
            return pd.DataFrame({cols[0]: list(keys)})
    
    # è½¬æ¢ä¿¡å·é”®ä¸ºDataFrame
    key_pn_df = idx_to_df(sig1_keys, key_pn)
    key_base_df_2 = idx_to_df(sig2_keys, key_base)
    key_base_df_3 = idx_to_df(sig3_keys, key_base)
    
    # æ”¶é›†æ‰€æœ‰å¤šè§„æ ¼base_names
    all_multi_base_names = set()
    
    # ä»Signal 1: product_name â†’ base_nameæ˜ å°„
    if not key_pn_df.empty:
        if has_store:
            pn_to_base_map = work.set_index([store_col, product_name_col])['base_name'].to_dict()
            for _, row in key_pn_df.iterrows():
                key = (row[store_col], row[product_name_col])
                if key in pn_to_base_map:
                    all_multi_base_names.add((row[store_col], pn_to_base_map[key]))
        else:
            pn_to_base_map = work.set_index(product_name_col)['base_name'].to_dict()
            for _, row in key_pn_df.iterrows():
                if row[product_name_col] in pn_to_base_map:
                    all_multi_base_names.add(pn_to_base_map[row[product_name_col]])
    
    # ä»Signal 2: ç›´æ¥ä½¿ç”¨base_name
    if not key_base_df_2.empty:
        for _, row in key_base_df_2.iterrows():
            if has_store:
                all_multi_base_names.add((row[store_col], row['base_name']))
            else:
                all_multi_base_names.add(row['base_name'])
    
    # ä»Signal 3: ç›´æ¥ä½¿ç”¨base_name
    if not key_base_df_3.empty:
        for _, row in key_base_df_3.iterrows():
            if has_store:
                all_multi_base_names.add((row[store_col], row['base_name']))
            else:
                all_multi_base_names.add(row['base_name'])
    
    print(f"  ğŸ“Š åˆå¹¶åå”¯ä¸€å¤šè§„æ ¼åŸºç¡€åç§°: {len(all_multi_base_names)} ä¸ª")
    
    # === Step 6: å‘é‡åŒ–è¿‡æ»¤ï¼ˆé¿å…é€è¡Œå¾ªç¯ï¼‰===
    if has_store:
        work['is_multi_spec'] = work.apply(
            lambda row: (row[store_col], row['base_name']) in all_multi_base_names,
            axis=1
        )
    else:
        work['is_multi_spec'] = work['base_name'].isin(all_multi_base_names)
    
    result = work[work['is_multi_spec']].copy()
    result = result.drop('is_multi_spec', axis=1)
    
    if result.empty:
        print("  âœ… æœªè¯†åˆ«åˆ°å¤šè§„æ ¼å•†å“")
        return pd.DataFrame()
    
    print(f"  âœ… ç­›é€‰åå¤šè§„æ ¼SKU: {len(result)} ä¸ª")
    
    # === Step 7: è®¡ç®—è§„æ ¼ç§ç±»æ•° ===
    print("  ğŸ”¢ è®¡ç®—è§„æ ¼ç§ç±»æ•°...")
    
    def _coalesce_variant(row):
        """ä¼˜å…ˆçº§åˆå¹¶ï¼šè§„æ ¼åˆ— > inferred_spec > barcode"""
        for c in [spec_col, 'inferred_spec', barcode_col]:
            if c not in row.index:
                continue
            v = row.get(c, None)
            if isinstance(v, str):
                v = v.strip()
            if v not in (None, '', 'nan') and not (isinstance(v, float) and np.isnan(v)):
                return v
        return None
    
    result['variant_key'] = result.apply(_coalesce_variant, axis=1)
    
    # æŒ‰base_nameç»Ÿè®¡unique variant_keys
    if has_store:
        vk_cnt = result.dropna(subset=['variant_key']).groupby(
            [store_col, 'base_name']
        )['variant_key'].nunique().reset_index()
        vk_cnt.columns = [store_col, 'base_name', 'è§„æ ¼ç§ç±»æ•°']
        result = result.merge(vk_cnt, on=[store_col, 'base_name'], how='left')
    else:
        vk_cnt = result.dropna(subset=['variant_key']).groupby(
            'base_name'
        )['variant_key'].nunique().reset_index()
        vk_cnt.columns = ['base_name', 'è§„æ ¼ç§ç±»æ•°']
        result = result.merge(vk_cnt, on='base_name', how='left')
    
    # å¡«å……ç¼ºå¤±å€¼ï¼ˆå‡è®¾è‡³å°‘2ä¸ªè§„æ ¼ï¼‰
    result['è§„æ ¼ç§ç±»æ•°'] = result['è§„æ ¼ç§ç±»æ•°'].fillna(2).astype(int)
    
    # === Step 8: æ ‡æ³¨ä¿¡å·æºï¼ˆå¤šè§„æ ¼ä¾æ®ï¼‰===
    print("  ğŸ·ï¸ æ ‡æ³¨è§¦å‘ä¿¡å·æº...")
    
    def get_trigger_for_row(row):
        """è·å–è§¦å‘è¯¥è¡Œçš„ä¿¡å·æº"""
        triggers = []
        
        if has_store:
            store_name = row[store_col]
            base_name = row['base_name']
            product_name = row[product_name_col]
            
            # æ£€æŸ¥Signal 1
            if not key_pn_df.empty:
                match = key_pn_df[
                    (key_pn_df[store_col] == store_name) & 
                    (key_pn_df[product_name_col] == product_name)
                ]
                if not match.empty:
                    triggers.append('è§„æ ¼åˆ—')
            
            # æ£€æŸ¥Signal 2
            if not key_base_df_2.empty:
                match = key_base_df_2[
                    (key_base_df_2[store_col] == store_name) & 
                    (key_base_df_2['base_name'] == base_name)
                ]
                if not match.empty:
                    triggers.append('åç§°è§£æ')
            
            # æ£€æŸ¥Signal 3
            if not key_base_df_3.empty:
                match = key_base_df_3[
                    (key_base_df_3[store_col] == store_name) & 
                    (key_base_df_3['base_name'] == base_name)
                ]
                if not match.empty:
                    triggers.append('æ¡ç å¤šå€¼')
        else:
            base_name = row['base_name']
            product_name = row[product_name_col]
            
            # æ£€æŸ¥Signal 1
            if not key_pn_df.empty and product_name in key_pn_df[product_name_col].values:
                triggers.append('è§„æ ¼åˆ—')
            
            # æ£€æŸ¥Signal 2
            if not key_base_df_2.empty and base_name in key_base_df_2['base_name'].values:
                triggers.append('åç§°è§£æ')
            
            # æ£€æŸ¥Signal 3
            if not key_base_df_3.empty and base_name in key_base_df_3['base_name'].values:
                triggers.append('æ¡ç å¤šå€¼')
        
        return ', '.join(triggers) if triggers else 'æœªçŸ¥'
    
    # æ€§èƒ½ä¼˜åŒ–ï¼šå¤§æ•°æ®é›†ä½¿ç”¨æ‰¹é‡æ ‡æ³¨
    if len(result) > 1000:
        result['å¤šè§„æ ¼ä¾æ®'] = 'æ‰¹é‡è¯†åˆ«'
        print(f"     âš ï¸ æ•°æ®é›†è¾ƒå¤§ ({len(result)} è¡Œ)ï¼Œä½¿ç”¨ç®€åŒ–æ ‡æ³¨")
    else:
        result['å¤šè§„æ ¼ä¾æ®'] = result.apply(get_trigger_for_row, axis=1)
        print(f"     âœ… å®Œæˆé€è¡Œæ ‡æ³¨")
    
    # === è¾“å‡ºç»Ÿè®¡ ===
    print("\n" + "="*60)
    print("ğŸ“‹ ã€å¤šè§„æ ¼è¯†åˆ«ç»“æœç»Ÿè®¡ã€‘")
    print("="*60)
    print(f"å¤šè§„æ ¼SKUæ€»æ•°: {len(result)}")
    print(f"å”¯ä¸€å¤šè§„æ ¼å•†å“æ•°: {result['base_name'].nunique()}")
    print(f"å¹³å‡è§„æ ¼ç§ç±»æ•°: {result['è§„æ ¼ç§ç±»æ•°'].mean():.1f}")
    print(f"æœ€å¤šè§„æ ¼å•†å“: {result['è§„æ ¼ç§ç±»æ•°'].max()} ç§")
    
    if 'å¤šè§„æ ¼ä¾æ®' in result.columns and result['å¤šè§„æ ¼ä¾æ®'].iloc[0] != 'æ‰¹é‡è¯†åˆ«':
        print("\nä¿¡å·æºåˆ†å¸ƒ:")
        for source, count in result['å¤šè§„æ ¼ä¾æ®'].value_counts().head(5).items():
            print(f"  - {source}: {count} ä¸ªSKU")
    
    return result


def analyze_competitor_multi_spec_from_original(excel_file: str, 
                                                 sheet_name: str = None,
                                                 product_name_col: str = 'å•†å“åç§°',
                                                 spec_col: str = 'è§„æ ¼åç§°', 
                                                 barcode_col: str = 'æ¡ç ') -> pd.DataFrame:
    """
    ä»ç«å¯¹åŸå§‹æ•°æ®ä¸­è¯†åˆ«å¤šè§„æ ¼å•†å“
    
    å‚æ•°:
        excel_file: ç«å¯¹åŸå§‹æ•°æ®Excelæ–‡ä»¶è·¯å¾„
        sheet_name: Sheetåç§°ï¼ˆé»˜è®¤è¯»å–ç¬¬ä¸€ä¸ªSheetï¼‰
        product_name_col: å•†å“åç§°åˆ—å
        spec_col: è§„æ ¼åˆ—å
        barcode_col: æ¡ç åˆ—å
    
    è¿”å›:
        å¤šè§„æ ¼å•†å“è¯¦æƒ…DataFrame
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“‚ è¯»å–ç«å¯¹åŸå§‹æ•°æ®: {excel_file}")
    print(f"{'='*60}")
    
    try:
        if sheet_name:
            df = pd.read_excel(excel_file, sheet_name=sheet_name)
        else:
            df = pd.read_excel(excel_file)
        
        print(f"âœ… æˆåŠŸè¯»å–ï¼Œå…± {len(df)} è¡Œæ•°æ®")
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        return pd.DataFrame()
    
    # è°ƒç”¨ä¸»è¯†åˆ«å‡½æ•°
    result = identify_multi_spec_products(
        df,
        product_name_col=product_name_col,
        spec_col=spec_col,
        barcode_col=barcode_col
    )
    
    return result


if __name__ == '__main__':
    """
    æµ‹è¯•è„šæœ¬ï¼šè¯»å–ç«å¯¹åŸå§‹æ•°æ®å¹¶è¯†åˆ«å¤šè§„æ ¼å•†å“
    """
    import sys
    from pathlib import Path
    
    # é»˜è®¤è·¯å¾„
    upload_dir = Path('upload/ç«å¯¹')
    
    if not upload_dir.exists():
        print(f"âŒ ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨: {upload_dir}")
        sys.exit(1)
    
    # æŸ¥æ‰¾Excelæ–‡ä»¶
    excel_files = list(upload_dir.glob('*.xlsx'))
    
    if not excel_files:
        print(f"âŒ æœªæ‰¾åˆ°Excelæ–‡ä»¶: {upload_dir}")
        sys.exit(1)
    
    print(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶:")
    for i, f in enumerate(excel_files, 1):
        print(f"  {i}. {f.name}")
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶
    excel_file = excel_files[0]
    
    print(f"\nä½¿ç”¨æ–‡ä»¶: {excel_file.name}")
    
    # æ‰§è¡Œè¯†åˆ«
    result = analyze_competitor_multi_spec_from_original(
        str(excel_file),
        product_name_col='å•†å“åç§°',
        spec_col='è§„æ ¼åç§°',
        barcode_col='æ¡ç '
    )
    
    if not result.empty:
        # ä¿å­˜ç»“æœ
        output_file = Path('reports') / f'ç«å¯¹å¤šè§„æ ¼å•†å“_{pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
        output_file.parent.mkdir(exist_ok=True)
        
        # æŒ‰base_nameåˆ†ç»„ç»Ÿè®¡
        summary = result.groupby('base_name').agg({
            'product_name': 'count',
            'è§„æ ¼ç§ç±»æ•°': 'first',
            'å¤šè§„æ ¼ä¾æ®': 'first'
        }).rename(columns={'product_name': 'SKUæ•°'}).reset_index()
        summary = summary.rename(columns={'base_name': 'å•†å“åŸºç¡€åç§°'})
        summary = summary.sort_values('SKUæ•°', ascending=False)
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # Sheet 1: æ±‡æ€»
            summary.to_excel(writer, sheet_name='å¤šè§„æ ¼å•†å“æ±‡æ€»', index=False)
            
            # Sheet 2: è¯¦ç»†åˆ—è¡¨
            result.to_excel(writer, sheet_name='å¤šè§„æ ¼SKUè¯¦ç»†', index=False)
        
        print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_file}")
        print(f"   - Sheet 1: å¤šè§„æ ¼å•†å“æ±‡æ€» ({len(summary)} ä¸ªå•†å“)")
        print(f"   - Sheet 2: å¤šè§„æ ¼SKUè¯¦ç»† ({len(result)} ä¸ªSKU)")
    else:
        print("\nâš ï¸ æœªè¯†åˆ«åˆ°å¤šè§„æ ¼å•†å“")
