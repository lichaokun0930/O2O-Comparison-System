#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Streamlit å®‰å…¨å¯åŠ¨å™¨ - åœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡
è¿™ä¸ªè„šæœ¬å¿…é¡»åœ¨æ‰€æœ‰å…¶ä»–å¯¼å…¥ä¹‹å‰è¿è¡Œ
"""

# ============================================================================
# ç¬¬ä¸€æ­¥ï¼šè®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆåœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰ï¼‰
# ============================================================================
import os
import sys

# å¼ºåˆ¶ CPU æ¨¡å¼ï¼Œç¦ç”¨æ‰€æœ‰ CUDA ç›¸å…³åŠŸèƒ½
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['USE_TORCH_SIM'] = '0'
os.environ['ENCODE_BATCH_SIZE'] = '32'
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # é¿å… Intel MKL å†²çª

# ç¦ç”¨ PyTorch CUDA
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'

print("=" * 60)
print("ğŸ›¡ï¸  å®‰å…¨æ¨¡å¼å¯åŠ¨å™¨")
print("=" * 60)
print("âœ… ç¯å¢ƒå˜é‡å·²è®¾ç½®ï¼ˆCPU æ¨¡å¼ï¼‰")
print("âœ… CUDA å·²ç¦ç”¨")
print("=" * 60)

# ============================================================================
# ç¬¬äºŒæ­¥ï¼šç°åœ¨å¯ä»¥å®‰å…¨åœ°å¯åŠ¨ Streamlit
# ============================================================================
if __name__ == "__main__":
    # è¿è¡Œ streamlit
    from streamlit.web import cli as stcli
    
    # è®¾ç½®å‚æ•°
    sys.argv = [
        "streamlit",
        "run",
        "comparison_app.py",
        "--server.port=8501",
        "--server.address=localhost",
    ]
    
    # å¯åŠ¨
    sys.exit(stcli.main())
